---
title: 'Lab 4: Exploratory Data Analysis'
format:
  html:
    self-contained: true
editor: source
knitr:
  opts_chunk:
    message: false
---

```{r}
#| include: TRUE
#| echo: false
library(tidyverse)

sqf_url <- "https://www1.nyc.gov/assets/nypd/downloads/zip/analysis_and_planning/stop-question-frisk/sqf-2011-csv.zip"
temp <- tempfile()
download.file(sqf_url, temp)
sqf_zip <- unzip(temp, "2011.csv")
sqf_2011 <- read.csv(sqf_zip, stringsAsFactors = FALSE) 
sqf_2011_race_cat <- read.csv("https://raw.githubusercontent.com/lindsaypoirier/STS-101/master/Data/SQF/sqf_race_categories.csv", stringsAsFactors = FALSE) 
rm(sqf_url)
rm(temp)
rm(sqf_zip)
```

```{r}
#| include: TRUE
#| echo: false
sqf_2011 <- 
  sqf_2011 |> 
  select(pct, race, age, frisked, pistol, riflshot, asltweap, knifcuti, machgun, othrweap, sumissue, arstmade) |>
  left_join(sqf_2011_race_cat, by = "race") |>
  mutate(across(frisked:arstmade, 
         ~ case_when(. == "Y" ~ 1, . == "N" ~ 0)))
rm(sqf_2011_race_cat)
```



```{r}
#| include: TRUE
#| echo: false
library(dplyr)
sqf_2011 <- 
  sqf_2011 |>
  #Add a variable for weapon found
  mutate(wpnfound = case_when(pistol == 1 |
                               riflshot == 1 | 
                               asltweap == 1 |
                               knifcuti == 1 | 
                               machgun == 1 | 
                               othrweap == 1 ~ 1,
                             TRUE ~ 0))
sqf_2011 <- 
  sqf_2011 |>
  #Add a variable for arrest made or summons issued
  mutate(arrestsumm = case_when(sumissue == 1 | 
                                arstmade == 1 ~ 1,
                               TRUE ~ 0))
```



```{r}
#| include: TRUE
#| echo: false
sqf_2011_1 <-
  sqf_2011 |>
  select(pct, arrestsumm, age, wpnfound, race_cat, frisked)
```


```{r}
#| include: TRUE
#| echo: false
total_stops <-
  sqf_2011 |>
  summarize(Count = n()) |>
  pull()

total_stops
```



```{r}
#| include: TRUE
#| echo: false
sqf_2011 |>
  #Subset to rows where suspect innocent
  filter(arrestsumm == 0) |> 
  #Calculate number of observations
  summarise(total_innocent = n(), 
            percent_innocent = n() / total_stops * 100)
```



```{r}
#| include: TRUE
#| echo: false
sqf_2011 |>
  #Subset to rows where suspect age 14-24
  filter(age >=14 & age <= 24) |> 
  #Calculate number of observations and percentage of observations
  summarise(total_14_24 = n(), 
            percent_14_24 = n() / total_stops * 100)
```


```{r}
#| include: TRUE
#| echo: false
total_stops_age_recorded <-
  sqf_2011 |>
  #Subset to rows where age is not 999
  filter(age != 999) |> 
  summarize(Count = n()) |>
  pull()

sqf_2011 |>
  filter(age >= 14 & age <= 24) |>
  summarize(total_14_24 = n(), 
            percent_14_24 = n() / total_stops_age_recorded * 100)
```



```{r}
#| include: TRUE
#| echo: false
total_stops_race_recorded <-
  sqf_2011 |>
  #Subset to rows where race_cat is not NA or "OTHER"
  filter(!is.na(race_cat) & race_cat != "OTHER") |> 
  summarize(Count = n()) |>
  pull()

sqf_2011 |>
  #Subset to rows where race_cat is not NA or "OTHER"
  filter(!is.na(race_cat) & race_cat != "OTHER") |> 
  #Group by race
  group_by(race_cat) |> 
  #Calculate number of observations
  summarise(stops = n(), 
            percent_stops = n() / total_stops_race_recorded * 100) |>
  #Sort by stops in descending order
  arrange(desc(stops)) 
```

Even though it can be difficult, data wrangling is where the real magic in data analysis happens. It's the skill of converting unstructured, unclean data into an orderly, structured format that can be analyzed. I now have a profound understanding of the significance of data consistency and quality because to my experience with data wrangling. Every stage of the wrangling process—from handling missing values to rearranging information and combining diverse sources—brings me one step closer to useful findings. The thrill of transforming disorganized material into something significant and useful is tremendously satisfying, even though it can occasionally be time-consuming and laborious. Data wrangling is a crucial skill in the resume of a data analyst because it lays the foundation for successful analysis.



